[2024-05-23 17:20:08,674][__main__][INFO] - fold:5
[2024-05-23 17:20:08,675][__main__][INFO] - train_subs:[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]
[2024-05-23 17:20:08,675][__main__][INFO] - val_subs:[5]
/home/ncclab/miniconda3/envs/att_model/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:263: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ncclab/miniconda3/envs/att_model/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory ./clisa_cp/SEED exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name      | Type             | Params
-----------------------------------------------
0 | model     | simpleNN3        | 41.3 K
1 | criterion | CrossEntropyLoss | 0
-----------------------------------------------
41.3 K    Trainable params
0         Non-trainable params
41.3 K    Total params
0.165     Total estimated model params size (MB)




Epoch 4:  93%|██████████████████████████████████████████████████████████▊    | 559/599 [00:03<00:00, 147.15it/s, loss=0.029, v_num=m93x, mlp/val/loss=0.472, mlp/val/acc=87.80, mlp/train/loss=0.0562, mlp/train/acc=98.30]



Epoch 6: 100%|██████████████████████████████████████████████████████████████| 599/599 [00:04<00:00, 144.47it/s, loss=0.0172, v_num=m93x, mlp/val/loss=0.535, mlp/val/acc=88.90, mlp/train/loss=0.0257, mlp/train/acc=99.50]



Epoch 8:  97%|████████████████████████████████████████████████████████████▍ | 584/599 [00:03<00:00, 157.50it/s, loss=0.0096, v_num=m93x, mlp/val/loss=0.565, mlp/val/acc=89.00, mlp/train/loss=0.0141, mlp/train/acc=99.90]






Epoch 12:  94%|████████████████████████████████████████████████████████▍   | 564/599 [00:03<00:00, 150.93it/s, loss=0.00641, v_num=m93x, mlp/val/loss=0.620, mlp/val/acc=89.10, mlp/train/loss=0.0075, mlp/train/acc=100.0]



















Epoch 23:  97%|███████████████████████████████████████████████████████████▎ | 583/599 [00:03<00:00, 156.87it/s, loss=0.0042, v_num=m93x, mlp/val/loss=0.603, mlp/val/acc=88.70, mlp/train/loss=0.0046, mlp/train/acc=100.0]



Epoch 26:  93%|███████████████████████████████████████████████████████    | 559/599 [00:03<00:00, 165.10it/s, loss=0.00449, v_num=m93x, mlp/val/loss=0.577, mlp/val/acc=89.60, mlp/train/loss=0.00435, mlp/train/acc=100.0]



































Epoch 46:  96%|████████████████████████████████████████████████████████▋  | 576/599 [00:03<00:00, 149.38it/s, loss=0.00428, v_num=m93x, mlp/val/loss=0.551, mlp/val/acc=89.70, mlp/train/loss=0.00402, mlp/train/acc=100.0]













Epoch 54:  93%|███████████████████████████████████████████████████████    | 559/599 [00:03<00:00, 167.11it/s, loss=0.00427, v_num=m93x, mlp/val/loss=0.547, mlp/val/acc=89.00, mlp/train/loss=0.00394, mlp/train/acc=100.0]





























Epoch 71:  93%|███████████████████████████████████████████████████████    | 559/599 [00:03<00:00, 162.61it/s, loss=0.00402, v_num=m93x, mlp/val/loss=0.555, mlp/val/acc=89.00, mlp/train/loss=0.00391, mlp/train/acc=100.0]

Epoch 72:  98%|██████████████████████████████████████████████████████████ | 590/599 [00:03<00:00, 170.00it/s, loss=0.00426, v_num=m93x, mlp/val/loss=0.552, mlp/val/acc=88.90, mlp/train/loss=0.00396, mlp/train/acc=100.0]





















Epoch 84:  93%|███████████████████████████████████████████████████████    | 559/599 [00:03<00:00, 157.55it/s, loss=0.00364, v_num=m93x, mlp/val/loss=0.534, mlp/val/acc=89.70, mlp/train/loss=0.00393, mlp/train/acc=100.0]

Epoch 85:  93%|███████████████████████████████████████████████████████    | 559/599 [00:03<00:00, 169.31it/s, loss=0.00394, v_num=m93x, mlp/val/loss=0.546, mlp/val/acc=89.40, mlp/train/loss=0.00395, mlp/train/acc=100.0]










Epoch 91:  93%|███████████████████████████████████████████████████████▉    | 559/599 [00:03<00:00, 158.44it/s, loss=0.00438, v_num=m93x, mlp/val/loss=0.531, mlp/val/acc=89.70, mlp/train/loss=0.0039, mlp/train/acc=100.0]

Epoch 92:  97%|█████████████████████████████████████████████████████████▎ | 582/599 [00:03<00:00, 151.01it/s, loss=0.00354, v_num=m93x, mlp/val/loss=0.546, mlp/val/acc=89.10, mlp/train/loss=0.00394, mlp/train/acc=100.0]








Epoch 96: 100%|███████████████████████████████████████████████████████████| 599/599 [00:03<00:00, 160.19it/s, loss=0.00361, v_num=m93x, mlp/val/loss=0.550, mlp/val/acc=88.90, mlp/train/loss=0.00393, mlp/train/acc=100.0]