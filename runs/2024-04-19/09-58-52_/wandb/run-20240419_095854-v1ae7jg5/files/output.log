
Global seed set to 7
load ext data finished!
fold: 0
Sanity Checking: 0it [00:00, ?it/s]
/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=[4])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[4])` instead.
  rank_zero_deprecation(
/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_ext.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
  | Name      | Type                | Params
--------------------------------------------------
0 | model     | Conv_att_simple_new | 133 K
1 | criterion | SimCLRLoss          | 0
--------------------------------------------------
133 K     Trainable params
0         Non-trainable params
133 K     Total params
























































Epoch 0:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:52<00:16,  2.80it/s, loss=2.97, v_num=7jg5]























































Epoch 1:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:52<00:16,  2.80it/s, loss=2.76, v_num=7jg5]






















































Epoch 2:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:53<00:16,  2.78it/s, loss=2.66, v_num=7jg5]

Validation DataLoader 0:  84%|███████████████████████████████████████████████████████████████████▌            | 38/45 [00:01<00:00, 28.44it/s]

`Trainer.fit` stopped: `max_epochs=3` reached.
fold: 1
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory ./CLISA_SeedV/v1ae7jg5/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
  | Name      | Type                | Params
--------------------------------------------------
0 | model     | Conv_att_simple_new | 133 K
1 | criterion | SimCLRLoss          | 0
--------------------------------------------------
133 K     Trainable params
0         Non-trainable params
133 K     Total params
0.533     Total estimated model params size (MB)






















































Epoch 0:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:51<00:15,  2.83it/s, loss=2.72, v_num=7jg5]





















































Epoch 1:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:52<00:16,  2.79it/s, loss=2.63, v_num=7jg5]























































Epoch 2:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:54<00:16,  2.74it/s, loss=2.61, v_num=7jg5]
Validation: 0it [00:00, ?it/s]

`Trainer.fit` stopped: `max_epochs=3` reached.
fold: 2
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
  | Name      | Type                | Params
--------------------------------------------------
0 | model     | Conv_att_simple_new | 133 K
1 | criterion | SimCLRLoss          | 0
--------------------------------------------------
133 K     Trainable params
0         Non-trainable params
133 K     Total params
0.533     Total estimated model params size (MB)





















































Epoch 0:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:52<00:16,  2.80it/s, loss=3.15, v_num=7jg5]























































Epoch 1:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [02:00<00:17,  2.62it/s, loss=3.05, v_num=7jg5]























































Epoch 2:  88%|██████████████████████████████████████████████████████████████▏        | 315/360 [01:57<00:16,  2.67it/s, loss=2.99, v_num=7jg5]

Validation: 0it [00:00, ?it/s]
`Trainer.fit` stopped: `max_epochs=3` reached.
fold: 3
Traceback (most recent call last):
  File "/home/gpt/grm/CLISA_Hydra/train_ext.py", line 155, in <module>
    main()
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home/gpt/anaconda3/envs/torch2/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gpt/grm/CLISA_Hydra/train_ext.py", line 57, in main
    data_train = data[list(train_sub)].reshape(-1, data.shape[-2], data.shape[-1])   # (train_subs*n_vids*30, 32, 250)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt